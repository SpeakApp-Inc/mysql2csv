#!/usr/bin/env python
'''
MySQL database to CSV file exporter

Copyright (c) 2014 Elcio Ferreira, Ricardo Lafuente
Licensed under the MIT license. See the LICENSE file for the full license text.

Check the README.md file for usage, or run

    mysql2csv --help

'''

import sys, os, datetime
import MySQLdb
import csv
import click
from dotenv import load_dotenv
import pickle
from googleapiclient.discovery import build
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.http import MediaFileUpload

def getCredentials():
    # Credentials management
    print "Getting credentials..."
    creds = None
    if os.path.exists('token.pickle'):
        with open('token.pickle', 'rb') as token:
            creds = pickle.load(token)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file('credentials.json',
                scopes=['https://www.googleapis.com/auth/drive.file', 'https://www.googleapis.com/auth/drive.metadata'])
            creds = flow.run_local_server(port=0)
        # Save the credentials for the next run
        with open('token.pickle', 'wb') as token:
            pickle.dump(creds, token)
    return creds

def fileUpload(creds, fileName, remoteFileName, folderId):
    # Drive API
    print "Uploading file to Google Drive..."
    drive_service = build('drive', 'v3', credentials=creds)

    # Call the Drive v3 API
    # filename = '2019-07-05_Users.csv'
    # folderid = '1bfhQ5TZm54CaVOBK1eYuOs_wgp2KttoO'
    file_metadata = {'name': remoteFileName, 'parents': [folderId]}
    media = MediaFileUpload(fileName, mimetype='text/csv', resumable=True)

    file = drive_service.files().create(body=file_metadata,
                                        media_body=media,
                                        fields='id').execute()


@click.command()
@click.option('-t', '--table', help='Table or tables to fetch (for more than one, use commas without spaces, e.g. "table1,table2,table3")', required=False)
@click.option('-l', '--list-only', help='List database tables and exit.', is_flag=True, default=False)
@click.option('-q', '--query', help='Custom SQL query.', required=False)
@click.option('-n', '--filename', help='Set exported csv filename.')
def export(table, list_only, query, filename):
    '''Export some or all tables in a MySQL database into CSV files.'''
    load_dotenv()
    hostname = os.getenv('mysql_host')
    user = os.getenv('mysql_user')
    password = os.getenv('mysql_pass')
    dbname = os.getenv('mysql_db')

    folderid = os.getenv('gdrive_folder_id')

    print "DB Name %s" % dbname

    # create the dir to place the CSV files in
    if not os.path.isdir(dbname):
        os.mkdir(dbname)

    # connect to the database
    db = MySQLdb.connect(hostname, user, password, dbname)

    credentials = getCredentials()
    # exit if there are no parameters
    if not list_only and not query and not table:
        return

    # check if list-only argument was specified
    if list_only:
        tables = db.cursor()
        tables.execute('SHOW TABLES')
        for table in tables:
            print table[0]
        return

    t = datetime.datetime.now()
    strDate = t.strftime('%Y-%m-%d')
    # check if custom query was called
    if query:
        print "Executing query..."
        if not filename:
            filename = "%s_query.csv" % strDate
        else:
            filename = '_'.join([strDate, filename + '.csv'])
        f = csv.writer(open(os.path.join(dbname, filename),'w'))
        rows = db.cursor()
        rows.execute(query)
        f.writerows(rows)
        fileUpload(credentials, os.path.join(dbname, filename), filename, folderid)
        return

    # check if table argument was specified
    if table:
        if len(table.split(',')) == 1:
            # only one table to fetch
            tables = [table]
        else:
            # multiple tables requested, make the tables list and go on
            tables = table.split(",")
    else:
        # get all tables
        tables = db.cursor()
        tables.execute('SHOW TABLES')

    for table in tables:
        print "Converting table %s...." % table
        filename = '_'.join([strDate, table + '.csv'])  #always use table name in case we are exporting many tables
        f = csv.writer(open(os.path.join(dbname, filename),'w'))
        colnames = db.cursor()
        colnames.execute('DESCRIBE %s' % table)
        f.writerow([i[0] for i in colnames])
        rows = db.cursor()
        rows.execute('SELECT * FROM %s' % table)
        f.writerows(rows)
        fileUpload(credentials, os.path.join(dbname, filename), filename, folderid)

if __name__=="__main__":
    export()
